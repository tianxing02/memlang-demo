"""
langgraph_agent.py

é€šä¿—è¯´æ˜ï¼š
- ä½¿ç”¨ LangGraph æ„å»ºä¸€ä¸ªæœ€å°åŒ–çš„â€œé—®ç­”ä»£ç†â€ï¼Œæ”¯æŒäº¤äº’ä¸éäº¤äº’ä¸¤ç§æ¨¡å¼ã€‚
- äº¤äº’æ¨¡å¼ï¼šè¯»å–ç”¨æˆ·è¾“å…¥ â†’ è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ â†’ æ‰“å°å¹¶è¿”å›çŠ¶æ€ã€‚
- éäº¤äº’æ¨¡å¼ï¼šè¯»å– state['query'] â†’ è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ï¼ˆåŒ…å«è®¤è¯é”™è¯¯å…œåº•ï¼‰ã€‚
"""

from dotenv import load_dotenv
import os
import json
from typing import TypedDict
from langgraph.graph import StateGraph
import openai

# å®šä¹‰çŠ¶æ€æ¨¡å¼ï¼ˆLangGraph æ–°ç‰ˆéœ€è¦æ˜¾å¼ state_schemaï¼‰
class AgentState(TypedDict, total=False):
    """ä»£ç†çš„æœ€å°çŠ¶æ€å®šä¹‰ï¼šä¿å­˜ç”¨æˆ·è¾“å…¥ä¸æ¨¡å‹å›å¤ã€‚"""
    query: str
    response: str

load_dotenv()  # åŠ è½½ .env æ–‡ä»¶

# è¯»å–å¹¶æ ¡éªŒ OPENAI_API_KEY
_api_key = os.getenv("OPENAI_API_KEY")
_api_base = os.getenv("OPENAI_API_BASE") 
_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# ä¸å‚è€ƒå®ç°ä¸€è‡´ï¼šä½¿ç”¨ openai.Clientï¼Œå¹¶æ”¯æŒ base_url
client = openai.Client(api_key=_api_key, base_url=_api_base)

def build_agent():
    """åˆ›å»ºäº¤äº’å¼ LangGraph æµç¨‹ï¼šå¾ªç¯è¯»å–è¾“å…¥å¹¶ç”Ÿæˆå›å¤ã€‚"""
    graph = StateGraph(AgentState)

    def ask_user(state):
        """è¯»å–ç”¨æˆ·è¾“å…¥ï¼Œå†™å…¥åˆ°çŠ¶æ€çš„ query å­—æ®µã€‚"""
        user_query = input("ğŸ‘¤ You: ")
        state["query"] = user_query
        return state

    def generate_response(state):
        """è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ï¼Œä¿å­˜åˆ°çŠ¶æ€å¹¶æ‰“å°ã€‚"""
        response = client.chat.completions.create(
            model=_model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯é çš„æ—¥ç¨‹ä¸ä»»åŠ¡åŠ©ç†ï¼Œå›ç­”åº”ç®€æ´ã€ç»“æ„åŒ–å¹¶å¯æ‰§è¡Œã€‚"},
                {"role": "user", "content": state.get("query", "")}
            ]
        )
        state["response"] = response.choices[0].message.content
        print("ğŸ¤– Assistant:", state["response"])
        return state

    graph.add_node("ask_user", ask_user)
    graph.add_node("generate_response", generate_response)
    graph.add_edge("ask_user", "generate_response")

    graph.set_entry_point("ask_user")
    return graph.compile()


def build_agent_noninteractive():
    """åˆ›å»ºéäº¤äº’ LangGraph æµç¨‹ï¼šä» state['query'] ç›´æ¥ç”Ÿæˆå›å¤ã€‚"""
    graph = StateGraph(AgentState)

    def generate_response(state):
        """è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ï¼›è®¤è¯å¤±è´¥æ—¶ç»™å‡ºä¸­æ–‡é”™è¯¯æç¤ºã€‚"""
        try:
            response = client.chat.completions.create(
                model=_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯é çš„æ—¥ç¨‹ä¸ä»»åŠ¡åŠ©ç†ï¼Œå›ç­”åº”ç®€æ´ã€ç»“æ„åŒ–å¹¶å¯æ‰§è¡Œã€‚"},
                    {"role": "user", "content": state.get("query", "")}
                ]
            )
            state["response"] = response.choices[0].message.content
        except openai.AuthenticationError:
            state["response"] = (
                "OpenAI API è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æœ‰æ•ˆã€‚"
                "å¦‚ä½¿ç”¨è‡ªæ‰˜ç®¡/ä»£ç†æœåŠ¡ï¼Œè¯·ç¡®è®¤ OPENAI_API_BASE å’Œæ¨¡å‹é…ç½®ã€‚"
            )
        print("ğŸ¤– Assistant:", state.get("response", ""))
        return state

    graph.add_node("generate_response", generate_response)
    graph.set_entry_point("generate_response")
    return graph.compile()
